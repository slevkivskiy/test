import asyncio
import logging
import os
import time  # <--- Ð”Ð¾Ð´Ð°Ð² Ð´Ð»Ñ Ð²Ð¸Ð¼Ñ–Ñ€ÑŽÐ²Ð°Ð½Ð½Ñ Ñ‡Ð°ÑÑƒ
import requests
import google.generativeai as genai
from dotenv import load_dotenv
from aiogram import Bot, Dispatcher, types, F
from aiogram.filters.command import Command
from aiogram.types import ReplyKeyboardMarkup, KeyboardButton
# --- ÐœÐ•Ð¢Ð Ð˜ÐšÐ˜ ---
from prometheus_client import start_http_server, Counter, Summary

# 1. Ð—Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð½Ñ
load_dotenv()
TOKEN = os.getenv("BOT_TOKEN")
WEATHER_KEY = os.getenv("WEATHER_API_KEY")
GEMINI_KEY = os.getenv("GEMINI_API_KEY")

# --- Ð’Ð˜Ð—ÐÐÐ§Ð•ÐÐÐ¯ ÐœÐ•Ð¢Ð Ð˜Ðš ---
# Ð›Ñ–Ñ‡Ð¸Ð»ÑŒÐ½Ð¸Ðº ÑƒÑÑ–Ñ… ÐºÐ¾Ð¼Ð°Ð½Ð´ (Ñ€Ð¾Ð·Ð±Ð¸Ð²Ð°Ñ”Ð¼Ð¾ Ð¿Ð¾ Ñ‚Ð¸Ð¿Ð°Ñ…: start, weather, ai)
COMMAND_COUNTER = Counter('bot_commands_total', 'Total commands', ['command_type'])
# Ð›Ñ–Ñ‡Ð¸Ð»ÑŒÐ½Ð¸Ðº Ð¿Ð¾Ð¼Ð¸Ð»Ð¾Ðº
ERROR_COUNTER = Counter('bot_errors_total', 'Total errors', ['error_type'])
# Ð§Ð°Ñ Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ñ– AI
AI_LATENCY = Summary('bot_ai_latency_seconds', 'Time spent processing AI request')
# Ð§Ð°Ñ Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ñ– ÐŸÐ¾Ð³Ð¾Ð´Ð¸
WEATHER_LATENCY = Summary('bot_weather_latency_seconds', 'Time spent fetching weather')


# 2. ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ AI Ð· ÐÐ’Ð¢ÐžÐŸÐžÐ¨Ð£ÐšÐžÐœ ÐœÐžÐ”Ð•Ð›Ð† (Ð¢Ð²Ñ–Ð¹ Ñ€Ð¾Ð±Ð¾Ñ‡Ð¸Ð¹ ÐºÐ¾Ð´)
model = None
if GEMINI_KEY:
    try:
        genai.configure(api_key=GEMINI_KEY)
        
        # --- Ð”Ð†ÐÐ“ÐÐžÐ¡Ð¢Ð˜ÐšÐ ---
        print("ðŸ” Ð¨Ð£ÐšÐÐ® Ð”ÐžÐ¡Ð¢Ð£ÐŸÐÐ† ÐœÐžÐ”Ð•Ð›Ð†...")
        available_models = []
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods:
                available_models.append(m.name)
        
        print(f"ðŸ“‹ Ð¡ÐŸÐ˜Ð¡ÐžÐš ÐœÐžÐ”Ð•Ð›Ð•Ð™: {available_models}")

        if available_models:
            selected_model = available_models[0]
            for m in available_models:
                if 'flash' in m:
                    selected_model = m
                    break
            
            print(f"âœ… ÐžÐ‘Ð ÐÐÐž ÐœÐžÐ”Ð•Ð›Ð¬: {selected_model}")
            model = genai.GenerativeModel(selected_model)
        else:
            print("âŒ ÐÐ•ÐœÐÐ„ Ð”ÐžÐ¡Ð¢Ð£ÐŸÐÐ˜Ð¥ ÐœÐžÐ”Ð•Ð›Ð•Ð™ Ð”Ð›Ð¯ Ð¦Ð¬ÐžÐ“Ðž ÐšÐ›Ð®Ð§Ð!")
            
    except Exception as e:
        print(f"âŒ ÐŸÐžÐœÐ˜Ð›ÐšÐ ÐŸÐ†Ð”ÐšÐ›Ð®Ð§Ð•ÐÐÐ¯ AI: {e}")

# 3. Ð‘Ð¾Ñ‚
logging.basicConfig(level=logging.INFO)
bot = Bot(token=TOKEN)
dp = Dispatcher()

kb = ReplyKeyboardMarkup(
    keyboard=[[KeyboardButton(text="ðŸŒ¦ ÐŸÐ¾Ð³Ð¾Ð´Ð° Ð‘Ñ€ÑƒÑÐ¸Ð»Ñ–Ð²")]],
    resize_keyboard=True
)

@dp.message(Command("start"))
async def cmd_start(message: types.Message):
    # ÐœÐµÑ‚Ñ€Ð¸ÐºÐ°: Ñ…Ñ‚Ð¾ÑÑŒ Ð½Ð°Ñ‚Ð¸ÑÐ½ÑƒÐ² ÑÑ‚Ð°Ñ€Ñ‚
    COMMAND_COUNTER.labels(command_type='start').inc()
    await message.answer("Ð¯ Ð¶Ð¸Ð²Ð¸Ð¹! ðŸ¤–\nÐŸÐ¸ÑˆÐ¸ Ð¼ÐµÐ½Ñ–, Ñ ÑÐ¿Ñ€Ð¾Ð±ÑƒÑŽ Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–ÑÑ‚Ð¸.", reply_markup=kb)

@dp.message(F.text == "ðŸŒ¦ ÐŸÐ¾Ð³Ð¾Ð´Ð° Ð‘Ñ€ÑƒÑÐ¸Ð»Ñ–Ð²")
async def weather_handler(message: types.Message):
    # ÐœÐµÑ‚Ñ€Ð¸ÐºÐ°: Ð·Ð°Ð¿Ð¸Ñ‚ Ð¿Ð¾Ð³Ð¾Ð´Ð¸
    COMMAND_COUNTER.labels(command_type='weather').inc()
    
    start_time = time.time() # â± Ð—Ð°ÑÑ–ÐºÐ°Ñ”Ð¼Ð¾ Ñ‡Ð°Ñ
    try:
        url = f"http://api.openweathermap.org/data/2.5/weather?q=Brusyliv&appid={WEATHER_KEY}&units=metric&lang=ua"
        data = requests.get(url).json()
        
        # ÐœÐµÑ‚Ñ€Ð¸ÐºÐ°: ÑÐºÑ–Ð»ÑŒÐºÐ¸ Ñ‡Ð°ÑÑƒ Ñ†Ðµ Ð·Ð°Ð¹Ð½ÑÐ»Ð¾
        duration = time.time() - start_time
        WEATHER_LATENCY.observe(duration)

        temp = data["main"]["temp"]
        await message.answer(f"Ð¢ÐµÐ¼Ð¿ÐµÑ€Ð°Ñ‚ÑƒÑ€Ð°: {temp}Â°C")
    except Exception as e:
        # ÐœÐµÑ‚Ñ€Ð¸ÐºÐ°: Ð¿Ð¾Ð¼Ð¸Ð»ÐºÐ°
        ERROR_COUNTER.labels(error_type='weather').inc()
        await message.answer("ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¿Ð¾Ð³Ð¾Ð´Ð¸.")

@dp.message()
async def ai_chat(message: types.Message):
    # ÐœÐµÑ‚Ñ€Ð¸ÐºÐ°: Ð¿Ð¸ÑˆÑƒÑ‚ÑŒ Ð² AI
    COMMAND_COUNTER.labels(command_type='ai_chat').inc()

    if not model:
        await message.answer("âš ï¸ ÐœÐ¾Ñ— Ð¼Ñ–Ð·ÐºÐ¸ Ð½Ðµ Ð¿Ñ€Ð°Ñ†ÑŽÑŽÑ‚ÑŒ. ÐÐ´Ð¼Ñ–Ð½, Ð´Ð¸Ð²Ð¸ÑÑŒ Ð»Ð¾Ð³Ð¸!")
        return

    await bot.send_chat_action(chat_id=message.chat.id, action="typing")
    
    start_time = time.time() # â± Ð—Ð°ÑÑ–ÐºÐ°Ñ”Ð¼Ð¾ Ñ‡Ð°Ñ
    try:
        response = model.generate_content(message.text)
        
        # ÐœÐµÑ‚Ñ€Ð¸ÐºÐ°: ÑÐºÑ–Ð»ÑŒÐºÐ¸ Ð´ÑƒÐ¼Ð°Ð² AI
        duration = time.time() - start_time
        AI_LATENCY.observe(duration)

        await message.answer(response.text, parse_mode="Markdown")
    except Exception as e:
        # ÐœÐµÑ‚Ñ€Ð¸ÐºÐ°: Ð¿Ð¾Ð¼Ð¸Ð»ÐºÐ° AI
        ERROR_COUNTER.labels(error_type='ai_error').inc()
        await message.answer(f"ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ°: {e}")

async def main():
    # ðŸ”¥ Ð—ÐÐŸÐ£Ð¡Ðš Ð¡Ð•Ð Ð’Ð•Ð Ð ÐœÐ•Ð¢Ð Ð˜Ðš (ÐŸÐ¾Ñ€Ñ‚ 8000)
    start_http_server(8000)
    print("ðŸ“ˆ Metrics server running on port 8000")
    
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())