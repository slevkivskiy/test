import asyncio
import logging
import os
import time  # <--- Ð”Ð»Ñ Ð·Ð°Ð¼Ñ–Ñ€Ñƒ Ñ‡Ð°ÑÑƒ
import requests
import google.generativeai as genai
from dotenv import load_dotenv
from aiogram import Bot, Dispatcher, types, F
from aiogram.filters.command import Command
from aiogram.types import ReplyKeyboardMarkup, KeyboardButton
from prometheus_client import start_http_server, Counter, Summary  # <--- ÐÐ¾Ð²Ñ– Ñ–Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ð¸

# --- 1. CONFIG & METRICS DEFINITION ---
load_dotenv()
TOKEN = os.getenv("BOT_TOKEN")
WEATHER_KEY = os.getenv("WEATHER_API_KEY")
GEMINI_KEY = os.getenv("GEMINI_API_KEY")

# ðŸ”¥ ÐœÐ•Ð¢Ð Ð˜ÐšÐ˜ (HARDCORE LEVEL)
# 1. Ð—Ð°Ð³Ð°Ð»ÑŒÐ½Ð¸Ð¹ Ð»Ñ–Ñ‡Ð¸Ð»ÑŒÐ½Ð¸Ðº ÐºÐ¾Ð¼Ð°Ð½Ð´ (Ñ€Ð¾Ð·Ð±Ð¸Ð²Ð°Ñ”Ð¼Ð¾ Ð¿Ð¾ Ñ‚Ð¸Ð¿Ð°Ñ…: Ð¿Ð¾Ð³Ð¾Ð´Ð°, ai, ÑÑ‚Ð°Ñ€Ñ‚)
COMMAND_COUNTER = Counter('bot_commands_total', 'Total number of commands', ['command_type'])

# 2. Ð›Ñ–Ñ‡Ð¸Ð»ÑŒÐ½Ð¸Ðº Ð¿Ð¾Ð¼Ð¸Ð»Ð¾Ðº (Ñ‰Ð¾Ð± Ð·Ð½Ð°Ñ‚Ð¸, ÐºÐ¾Ð»Ð¸ Ð²ÑÐµ Ð³Ð¾Ñ€Ð¸Ñ‚ÑŒ)
ERROR_COUNTER = Counter('bot_errors_total', 'Total number of errors', ['error_type'])

# 3. Ð¢Ð°Ð¹Ð¼ÐµÑ€: ÑÐºÑ–Ð»ÑŒÐºÐ¸ Ñ‡Ð°ÑÑƒ Ð¨Ð† Ð³ÐµÐ½ÐµÑ€ÑƒÑ” Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´ÑŒ (Latency)
AI_LATENCY = Summary('bot_ai_latency_seconds', 'Time spent processing AI request')

# 4. Ð¢Ð°Ð¹Ð¼ÐµÑ€: ÑÐºÑ–Ð»ÑŒÐºÐ¸ Ñ‡Ð°ÑÑƒ Ð·Ð°Ð¹Ð¼Ð°Ñ” Ð·Ð°Ð¿Ð¸Ñ‚ Ð¿Ð¾Ð³Ð¾Ð´Ð¸
WEATHER_LATENCY = Summary('bot_weather_latency_seconds', 'Time spent fetching weather')

# --- 2. SETUP AI ---
model = None
if GEMINI_KEY:
    try:
        genai.configure(api_key=GEMINI_KEY)
        model = genai.GenerativeModel('gemini-1.5-flash')
    except Exception as e:
        logging.error(f"AI Setup Error: {e}")

logging.basicConfig(level=logging.INFO)
bot = Bot(token=TOKEN)
dp = Dispatcher()

kb = ReplyKeyboardMarkup(
    keyboard=[[KeyboardButton(text="ðŸŒ¦ ÐŸÐ¾Ð³Ð¾Ð´Ð° Ð‘Ñ€ÑƒÑÐ¸Ð»Ñ–Ð²")]],
    resize_keyboard=True
)

# --- 3. HANDLERS WITH METRICS ---

@dp.message(Command("start"))
async def cmd_start(message: types.Message):
    # Ð Ð°Ñ…ÑƒÑ”Ð¼Ð¾ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñƒ
    COMMAND_COUNTER.labels(command_type='start').inc()
    
    await message.answer("ÐœÐ¾Ð½Ñ–Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ Ð°ÐºÑ‚Ð¸Ð²Ð¾Ð²Ð°Ð½Ð¾. Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð¸ Ð² Ð½Ð¾Ñ€Ð¼Ñ–. ðŸŸ¢", reply_markup=kb)

@dp.message(F.text == "ðŸŒ¦ ÐŸÐ¾Ð³Ð¾Ð´Ð° Ð‘Ñ€ÑƒÑÐ¸Ð»Ñ–Ð²")
async def weather_handler(message: types.Message):
    # Ð Ð°Ñ…ÑƒÑ”Ð¼Ð¾ Ð·Ð°Ð¿Ð¸Ñ‚
    COMMAND_COUNTER.labels(command_type='weather').inc()
    
    start_time = time.time() # â± Ð—Ð°ÑÑ–ÐºÐ°Ñ”Ð¼Ð¾ Ñ‡Ð°Ñ
    try:
        url = f"http://api.openweathermap.org/data/2.5/weather?q=Brusyliv&appid={WEATHER_KEY}&units=metric&lang=ua"
        data = requests.get(url).json()
        
        # Ð¤Ñ–ÐºÑÑƒÑ”Ð¼Ð¾ Ñ‡Ð°Ñ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ
        duration = time.time() - start_time
        WEATHER_LATENCY.observe(duration)
        
        temp = data["main"]["temp"]
        await message.answer(f"ðŸŒ¡ {temp}Â°C (Ð—Ð°Ð¿Ð¸Ñ‚ Ð·Ð°Ð¹Ð½ÑÐ²: {duration:.2f}Ñ)")
    except Exception as e:
        ERROR_COUNTER.labels(error_type='weather_api').inc()
        await message.answer("âš ï¸ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¿Ð¾Ð³Ð¾Ð´Ð¸.")

@dp.message()
async def ai_chat(message: types.Message):
    # Ð Ð°Ñ…ÑƒÑ”Ð¼Ð¾ Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½Ð½Ñ Ð´Ð¾ AI
    COMMAND_COUNTER.labels(command_type='ai_chat').inc()
    
    if not model:
        await message.answer("âš ï¸ AI Ð²Ð¸Ð¼ÐºÐ½ÐµÐ½Ð¾.")
        return

    await bot.send_chat_action(chat_id=message.chat.id, action="typing")
    
    start_time = time.time() # â± Ð—Ð°ÑÑ–ÐºÐ°Ñ”Ð¼Ð¾, ÑÐºÑ–Ð»ÑŒÐºÐ¸ Ð´ÑƒÐ¼Ð°Ñ” Gemini
    try:
        response = model.generate_content(message.text)
        
        duration = time.time() - start_time
        AI_LATENCY.observe(duration) # Ð—Ð°Ð¿Ð¸ÑÑƒÑ”Ð¼Ð¾ Ð² Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸
        
        await message.answer(response.text, parse_mode="Markdown")
    except Exception as e:
        ERROR_COUNTER.labels(error_type='ai_generation').inc()
        await message.answer(f"ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° AI: {e}")

async def main():
    # Ð—Ð°Ð¿ÑƒÑÐºÐ°Ñ”Ð¼Ð¾ ÑÐµÑ€Ð²ÐµÑ€ Ð¼ÐµÑ‚Ñ€Ð¸Ðº Ð½Ð° 8000 Ð¿Ð¾Ñ€Ñ‚Ñƒ
    start_http_server(8000)
    logging.info("ðŸ”¥ PRO Metrics server running on port 8000")
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())