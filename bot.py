import asyncio
import logging
import os
import time
import requests
import google.generativeai as genai
from dotenv import load_dotenv
from aiogram import Bot, Dispatcher, types, F
from aiogram.filters.command import Command
from aiogram.types import ReplyKeyboardMarkup, KeyboardButton

# --- –ú–ï–¢–†–ò–ö–ò (–ë–µ–∑ –ø–∞–¥—ñ–Ω–Ω—è, —è–∫—â–æ –Ω–µ–º–∞—î –ª—ñ–±–∏) ---
try:
    from prometheus_client import start_http_server, Counter, Summary
    PROMETHEUS_AVAILABLE = True
except ImportError:
    PROMETHEUS_AVAILABLE = False

# --- 1. –ö–û–ù–§–Ü–ì ---
load_dotenv()
TOKEN = os.getenv("BOT_TOKEN")
WEATHER_KEY = os.getenv("WEATHER_API_KEY")
GEMINI_KEY = os.getenv("GEMINI_API_KEY")

# --- 2. –ú–ï–¢–†–ò–ö–ò ---
if PROMETHEUS_AVAILABLE:
    COMMAND_COUNTER = Counter('bot_commands_total', 'Total commands', ['command_type'])
    ERROR_COUNTER = Counter('bot_errors_total', 'Total errors', ['error_type'])
    AI_LATENCY = Summary('bot_ai_latency_seconds', 'AI processing time')
    WEATHER_LATENCY = Summary('bot_weather_latency_seconds', 'Weather fetch time')

# --- 3. –ù–ï–ü–†–û–ë–ò–í–ù–ï –ü–Ü–î–ö–õ–Æ–ß–ï–ù–ù–Ø AI ---
model = None

def force_connect_ai():
    global model
    if not GEMINI_KEY:
        print("‚ùå –ö–ª—é—á–∞ –Ω–µ–º–∞—î!")
        return

    try:
        genai.configure(api_key=GEMINI_KEY)
        
        # –°–ü–ò–°–û–ö –ù–ê–î–Ü–á: –ü—Ä–æ–±—É—î–º–æ –ø–æ —á–µ—Ä–∑—ñ
        candidates = [
            'gemini-1.5-flash', # –ù–∞–π–∫—Ä–∞—â–∞
            'gemini-1.5-flash-001', # –°—Ç–∞–±—ñ–ª—å–Ω–∞ –≤–µ—Ä—Å—ñ—è
            'gemini-pro',       # –°—Ç–∞—Ä–∞ –¥–æ–±—Ä–∞ (–∑–∞–≤–∂–¥–∏ –ø—Ä–∞—Ü—é—î)
            'gemini-1.0-pro'    # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∞ –Ω–∞–∑–≤–∞ —Å—Ç–∞—Ä–æ—ó
        ]
        
        for candidate in candidates:
            try:
                print(f"üîÑ –ü—Ä–æ–±—É—é –ø—ñ–¥–∫–ª—é—á–∏—Ç–∏: {candidate}...")
                test_model = genai.GenerativeModel(candidate)
                # –¢–µ—Å—Ç–æ–≤–∏–π –ø—ñ–Ω–≥ (–≥–µ–Ω–µ—Ä–∞—Ü—ñ—è 1 —Ç–æ–∫–µ–Ω–∞), —â–æ–± –ø–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —á–∏ –ø—Ä–∞—Ü—é—î
                test_model.generate_content("Hi") 
                
                # –Ø–∫—â–æ –¥—ñ–π—à–ª–∏ —Å—é–¥–∏ - –º–æ–¥–µ–ª—å —Ä–æ–±–æ—á–∞!
                model = test_model
                print(f"‚úÖ –£–°–ü–Ü–•! –ü—Ä–∞—Ü—é—î–º–æ –Ω–∞: {candidate}")
                return
            except Exception as e:
                print(f"‚ö†Ô∏è {candidate} –Ω–µ –ø—ñ–¥—ñ–π—à–ª–∞: {e}")
                continue
        
        print("‚ùå –ñ–æ–¥–Ω–∞ –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–ø—É—Å—Ç–∏–ª–∞—Å—å. –¶–µ —Ñ—ñ–∞—Å–∫–æ.")

    except Exception as e:
        print(f"üíÄ –ö—Ä–∏—Ç–∏—á–Ω–∞ –ø–æ–º–∏–ª–∫–∞ AI: {e}")

# –ó–∞–ø—É—Å–∫–∞—î–º–æ –ø—ñ–¥–±—ñ—Ä
force_connect_ai()

logging.basicConfig(level=logging.INFO)
bot = Bot(token=TOKEN)
dp = Dispatcher()

kb = ReplyKeyboardMarkup(
    keyboard=[[KeyboardButton(text="üå¶ –ü–æ–≥–æ–¥–∞ –ë—Ä—É—Å–∏–ª—ñ–≤")]],
    resize_keyboard=True
)

@dp.message(Command("start"))
async def cmd_start(message: types.Message):
    if PROMETHEUS_AVAILABLE:
        COMMAND_COUNTER.labels(command_type='start').inc()
    await message.answer("–ë–æ—Ç –ø–µ—Ä–µ–∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ. –†–µ–∂–∏–º –≤–∏–∂–∏–≤–∞–Ω–Ω—è –∞–∫—Ç–∏–≤–æ–≤–∞–Ω–æ. üõ°", reply_markup=kb)

@dp.message(F.text == "üå¶ –ü–æ–≥–æ–¥–∞ –ë—Ä—É—Å–∏–ª—ñ–≤")
async def weather_handler(message: types.Message):
    if PROMETHEUS_AVAILABLE:
        COMMAND_COUNTER.labels(command_type='weather').inc()
    
    start_time = time.time()
    try:
        url = f"http://api.openweathermap.org/data/2.5/weather?q=Brusyliv&appid={WEATHER_KEY}&units=metric&lang=ua"
        data = requests.get(url).json()
        
        if PROMETHEUS_AVAILABLE:
            WEATHER_LATENCY.observe(time.time() - start_time)
        
        temp = data["main"]["temp"]
        await message.answer(f"üå° –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: {temp}¬∞C")
    except Exception as e:
        if PROMETHEUS_AVAILABLE:
            ERROR_COUNTER.labels(error_type='weather_api').inc()
        await message.answer(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –ø–æ–≥–æ–¥–∏: {e}")

@dp.message()
async def ai_chat(message: types.Message):
    if PROMETHEUS_AVAILABLE:
        COMMAND_COUNTER.labels(command_type='ai_chat').inc()

    if not model:
        await message.answer("‚ùå AI –∑–¥–æ—Ö –æ—Å—Ç–∞—Ç–æ—á–Ω–æ. –î–∏–≤–∏—Å—å –ª–æ–≥–∏.")
        return

    await bot.send_chat_action(chat_id=message.chat.id, action="typing")
    
    start_time = time.time()
    try:
        response = model.generate_content(message.text)
        
        if PROMETHEUS_AVAILABLE:
            AI_LATENCY.observe(time.time() - start_time)
        
        await message.answer(response.text)
        
    except Exception as e:
        err_msg = str(e)
        if "429" in err_msg:
            if PROMETHEUS_AVAILABLE:
                ERROR_COUNTER.labels(error_type='ai_rate_limit').inc()
            await message.answer("‚è≥ –õ—ñ–º—ñ—Ç. –ü–æ—á–µ–∫–∞–π —Ç—Ä–æ—Ö–∏.")
        else:
            if PROMETHEUS_AVAILABLE:
                ERROR_COUNTER.labels(error_type='ai_error').inc()
            await message.answer(f"Error: {err_msg}")

async def main():
    if PROMETHEUS_AVAILABLE:
        start_http_server(8000)
        logging.info("üî• Metrics server running on port 8000")
        
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())